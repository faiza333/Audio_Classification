{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riyfvEvvD9Qa"
      },
      "source": [
        "# 1. Setup and Get Data\n",
        "# 1.1 Install Dependencies and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "CMgXfDtND9Qg"
      },
      "outputs": [],
      "source": [
        "!pip install labelme tensorflow tensorflow-gpu opencv-python matplotlib albumentations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Vd-HpHJLeZk",
        "outputId": "f999a30d-ef1a-4ecf-cdff-0c28f2516b79"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "ZOy8zdMMD9Ql",
        "outputId": "1fc2e483-c42e-4062-f9ad-566ea364be51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opencv-python-headless 4.6.0.66\n",
            "Uninstalling opencv-python-headless-4.6.0.66:\n",
            "  Successfully uninstalled opencv-python-headless-4.6.0.66\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall opencv-python-headless -y \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dViKgxXND9Qm"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lGX-f9ZD9Qn"
      },
      "source": [
        "# 1.2 Collect Images Using OpenCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "OPy4OqeFD9Qo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import uuid\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "Gr28-qzQD9Qp"
      },
      "outputs": [],
      "source": [
        "IMAGES_PATH = os.path.join('data', 'images')\n",
        "number_images = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "fDqqWVSlD9Qr"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture('d.mp4')\n",
        "for imgnum in range(number_images):\n",
        "    print('Collecting image {}'.format(imgnum))\n",
        "    ret, frame = cap.read()\n",
        "    imgname = os.path.join(IMAGES_PATH,f'{str(uuid.uuid1())}.jpg')\n",
        "    cv2.imwrite(imgname, frame)\n",
        "    cv2.imshow('frame', frame)\n",
        "    time.sleep(1.1)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFPBw0nID9Qs"
      },
      "source": [
        "# 1.3 Annotate Images with LabelMe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZcZnyD5D9Qt"
      },
      "outputs": [],
      "source": [
        "!labelme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EauLqiW7D9Qu"
      },
      "source": [
        "2. Review Dataset and Build Image Loading Function\n",
        "2.1 Import TF and Deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "UpUq3JyZD9Qv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import json\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2 Limit GPU Memory Growth"
      ],
      "metadata": {
        "id": "3IjyUL7WK8ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus: \n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "CO2v0R5FK4RA"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3cnl9H1NV72",
        "outputId": "43dc8a15-10c7-4b44-903a-fa757b8094bc"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.3 Load Image into TF Data Pipeline"
      ],
      "metadata": {
        "id": "eEjRQ3T8PrXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = tf.data.Dataset.list_files('/content/drive/MyDrive/face/data/images/*.jpg')"
      ],
      "metadata": {
        "id": "t4yaVegWNZOR"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "S-GPt_BiP67a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(x): \n",
        "    byte_img = tf.io.read_file(x)\n",
        "    img = tf.io.decode_jpeg(byte_img)\n",
        "    return img"
      ],
      "metadata": {
        "id": "APECGuF4QWzr"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = images.map(load_image)"
      ],
      "metadata": {
        "id": "uiSfTQrfZH28"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "A-SAzWSAZJkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(images)\n"
      ],
      "metadata": {
        "id": "5AkvoK39ZN3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.4 View Raw Images with Matplotlib"
      ],
      "metadata": {
        "id": "mRNIKveach5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_generator = images.batch(4).as_numpy_iterator()\n",
        "plot_images = image_generator.next()"
      ],
      "metadata": {
        "id": "JatUzoEMchBl"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
        "for idx, image in enumerate(plot_images):\n",
        "    ax[idx].imshow(image) \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tFZAH6_nc5xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Move the Matching Labels"
      ],
      "metadata": {
        "id": "ZrH_v2Hh3GKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in ['train','test','val']:\n",
        "    for file in os.listdir(os.path.join('/content/drive/MyDrive/face/data', folder, 'images')):\n",
        "        \n",
        "        filename = file.split('.')[0]+'.json'\n",
        "        existing_filepath = os.path.join('/content/drive/MyDrive/face/data','labels', filename)\n",
        "        if os.path.exists(existing_filepath): \n",
        "            new_filepath = os.path.join('/content/drive/MyDrive/face/data',folder,'labels',filename)\n",
        "            os.replace(existing_filepath, new_filepath)      "
      ],
      "metadata": {
        "id": "HCxOfMQcc71Y"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Apply Image Augmentation on Images and Labels using Albumentations\n",
        "# 4.1 Setup Albumentations Transform Pipeline\n"
      ],
      "metadata": {
        "id": "M8OT1yEkHRNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as alb"
      ],
      "metadata": {
        "id": "Ex5KuVVT3aoD"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmentor = alb.Compose([alb.RandomCrop(width=450, height=450), \n",
        "                         alb.HorizontalFlip(p=0.5), \n",
        "                         alb.RandomBrightnessContrast(p=0.2),\n",
        "                         alb.RandomGamma(p=0.2), \n",
        "                         alb.RGBShift(p=0.2), \n",
        "                         alb.VerticalFlip(p=0.5)], \n",
        "                       bbox_params=alb.BboxParams(format='albumentations', \n",
        "                                                  label_fields=['class_labels']))"
      ],
      "metadata": {
        "id": "mti_vVcQHUkx"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.2 Load a Test Image and Annotation with OpenCV and JSON"
      ],
      "metadata": {
        "id": "L_c1yD1dIfmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(os.path.join(\"/content/drive/MyDrive/face/data/train/images/309ce7ee-4f43-11ed-b526-ecf4bb72d1c6.jpg\"))\n"
      ],
      "metadata": {
        "id": "YI8fI-ANIZt5"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcLO65KgIyvg",
        "outputId": "7599ad0c-b58d-484a-e764-790911e3d40a"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(480, 640, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(\"/content/drive/MyDrive/face/data/train/labels/309ce7ee-4f43-11ed-b526-ecf4bb72d1c6.json\"), 'r') as f:\n",
        "    label = json.load(f)\n"
      ],
      "metadata": {
        "id": "uuaAoLMhIkJu"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label['shapes'][0]['points']"
      ],
      "metadata": {
        "id": "DYcQw9ddIl9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "id": "iyrgE3DgSddE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.3 Extract Coordinates and Rescale to Match Image Resolution\n"
      ],
      "metadata": {
        "id": "r9yoGk6BNNVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coords = [0,0,0,0]\n",
        "coords[0] = label['shapes'][0]['points'][0][0]\n",
        "coords[1] = label['shapes'][0]['points'][0][1]\n",
        "coords[2] = label['shapes'][0]['points'][1][0]\n",
        "coords[3] = label['shapes'][0]['points'][1][1]"
      ],
      "metadata": {
        "id": "xzoVSt4lJK4Q"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzE3ypBRNduk",
        "outputId": "5b21ccb3-81db-4fcd-96d2-153ce3e1558b"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[221.2919708029197, 231.11678832116786, 411.0729927007299, 409.21897810218974]"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coords = list(np.divide(coords, [640,480,640,480]))"
      ],
      "metadata": {
        "id": "yprdqfCbNe13"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coords"
      ],
      "metadata": {
        "id": "vp8_z30HRle_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.4 Apply Augmentations and View Results\n"
      ],
      "metadata": {
        "id": "fRZ99erJRsCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmented = augmentor(image=img, bboxes=[coords], class_labels=['face'])"
      ],
      "metadata": {
        "id": "spFsmbO6Rnsm"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented['bboxes'][0][2:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKyioRvGRzZU",
        "outputId": "a280318c-f344-4bd4-81e0-3d07e1fdfa57"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5437956204379562, 0.541962692619627)"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented['bboxes']"
      ],
      "metadata": {
        "id": "GoiCzveqR38a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.rectangle(augmented['image'], \n",
        "              tuple(np.multiply(augmented['bboxes'][0][:2], [450,450]).astype(int)),\n",
        "              tuple(np.multiply(augmented['bboxes'][0][2:], [450,450]).astype(int)), \n",
        "                    (255,0,0), 2)\n",
        "\n",
        "plt.imshow(augmented['image'])"
      ],
      "metadata": {
        "id": "Z9pDGldmR9hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Build and Run Augmentation Pipeline\n",
        "# 5.1 Run Augmentation Pipeline"
      ],
      "metadata": {
        "id": "afYeSm6KnMfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for partition in ['train','test','val']: \n",
        "    for image in os.listdir(os.path.join('/content/drive/MyDrive/face/data', partition, 'images')):\n",
        "        img = cv2.imread(os.path.join('/content/drive/MyDrive/face/data', partition, 'images', image))\n",
        "\n",
        "        coords = [0,0,0.00001,0.00001]\n",
        "        label_path = os.path.join('/content/drive/MyDrive/face/data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                label = json.load(f)\n",
        "\n",
        "            coords[0] = label['shapes'][0]['points'][0][0]\n",
        "            coords[1] = label['shapes'][0]['points'][0][1]\n",
        "            coords[2] = label['shapes'][0]['points'][1][0]\n",
        "            coords[3] = label['shapes'][0]['points'][1][1]\n",
        "            coords = list(np.divide(coords, [640,480,640,480]))\n",
        "\n",
        "        try: \n",
        "            for x in range(60):\n",
        "                augmented = augmentor(image=img, bboxes=[coords], class_labels=['face'])\n",
        "                cv2.imwrite(os.path.join('/content/drive/MyDrive/face/aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
        "\n",
        "                annotation = {}\n",
        "                annotation['image'] = image\n",
        "\n",
        "                if os.path.exists(label_path):\n",
        "                    if len(augmented['bboxes']) == 0: \n",
        "                        annotation['bbox'] = [0,0,0,0]\n",
        "                        annotation['class'] = 0 \n",
        "                    else: \n",
        "                        annotation['bbox'] = augmented['bboxes'][0]\n",
        "                        annotation['class'] = 1\n",
        "                else: \n",
        "                    annotation['bbox'] = [0,0,0,0]\n",
        "                    annotation['class'] = 0 \n",
        "\n",
        "\n",
        "                with open(os.path.join('/content/drive/MyDrive/face/aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
        "                    json.dump(annotation, f)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)"
      ],
      "metadata": {
        "id": "8gyZyCKkS_Mu"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.2 Load Augmented Images to Tensorflow Dataset"
      ],
      "metadata": {
        "id": "Y1oQRmQlr35C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = tf.data.Dataset.list_files('/content/drive/MyDrive/face/aug_data/train/images/*.jpg', shuffle=False)\n",
        "train_images = train_images.map(load_image)\n",
        "train_images = train_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
        "train_images = train_images.map(lambda x: x/255)"
      ],
      "metadata": {
        "id": "x9CVAGvrpaCt"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = tf.data.Dataset.list_files('/content/drive/MyDrive/face/aug_data/test/images/*.jpg', shuffle=False)\n",
        "test_images = test_images.map(load_image)\n",
        "test_images = test_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
        "test_images = test_images.map(lambda x: x/255)"
      ],
      "metadata": {
        "id": "97MEYFXysePJ"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_images = tf.data.Dataset.list_files('/content/drive/MyDrive/face/aug_data/test/images/*.jpg', shuffle=False)\n",
        "val_images = val_images.map(load_image)\n",
        "val_images = val_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
        "val_images = val_images.map(lambda x: x/255)"
      ],
      "metadata": {
        "id": "yYpm2bvDsz1p"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "LKg4V0jDs6oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Prepare Labels\n",
        "# 6.1 Build Label Loading Function"
      ],
      "metadata": {
        "id": "B9tTOqsft3g7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_labels(label_path):\n",
        "    with open(label_path.numpy(), 'r', encoding = \"utf-8\") as f:\n",
        "        label = json.load(f)\n",
        "        \n",
        "    return [label['class']], label['bbox']"
      ],
      "metadata": {
        "id": "oxNl_WQsty8I"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.2 Load Labels to Tensorflow Dataset"
      ],
      "metadata": {
        "id": "C2lYHqtPt96g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = tf.data.Dataset.list_files('/content/drive/MyDrive/face/aug_data/train/labels/*.json', shuffle=False)\n",
        "train_labels = train_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))\n"
      ],
      "metadata": {
        "id": "LDVoetdyt7P6"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = tf.data.Dataset.list_files('/content/drive/MyDrive/face/aug_data/test/labels/*.json', shuffle=False)\n",
        "test_labels = test_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))\n"
      ],
      "metadata": {
        "id": "2KMT5loquFyE"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_labels = tf.data.Dataset.list_files('/content/drive/MyDrive/face/aug_data/val/labels/*.json', shuffle=False)\n",
        "val_labels = val_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))\n"
      ],
      "metadata": {
        "id": "LNRIu9fMuHZO"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "NXPUHrnuuJoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Combine Label and Image Samples\n",
        "# 7.1 Check Partition Lengths "
      ],
      "metadata": {
        "id": "zLo6u30Jvuy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_images), len(train_labels), len(test_images), len(test_labels), len(val_images), len(val_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85Jh6ghvummV",
        "outputId": "86526d93-18bb-4e2c-d293-ad09dd84e114"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3600, 3600, 660, 660, 660, 660)"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.2 Create Final Datasets (Images/Labels)"
      ],
      "metadata": {
        "id": "pD5Yczmuw3ZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train = tf.data.Dataset.zip((train_images, train_labels))\n",
        "train = train.shuffle(5000)\n",
        "train = train.batch(8)\n",
        "train = train.prefetch(4)  "
      ],
      "metadata": {
        "id": "tm2cawhPv01i"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = tf.data.Dataset.zip((test_images, test_labels))\n",
        "test = test.shuffle(1300)\n",
        "test = test.batch(8)\n",
        "test = test.prefetch(4)"
      ],
      "metadata": {
        "id": "WLgrmA2mw6KP"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = tf.data.Dataset.zip((val_images, val_labels))\n",
        "val = val.shuffle(1000)\n",
        "val = val.batch(8)\n",
        "val = val.prefetch(4)\n"
      ],
      "metadata": {
        "id": "NpMw4fj8w9Uv"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.as_numpy_iterator().next()[1]"
      ],
      "metadata": {
        "id": "9v48acmOw_9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.3 View Images and Annotations"
      ],
      "metadata": {
        "id": "B1gaxYo2xXuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_samples = train.as_numpy_iterator()\n"
      ],
      "metadata": {
        "id": "jfzOIj2jxRq_"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = data_samples.next()"
      ],
      "metadata": {
        "id": "1y88ucB9xr7k"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
        "for idx in range(4): \n",
        "    sample_image = res[0][idx]\n",
        "    sample_coords = res[1][1][idx]\n",
        "    \n",
        "    cv2.rectangle(sample_image, \n",
        "                  tuple(np.multiply(sample_coords[:2], [120,120]).astype(int)),\n",
        "                  tuple(np.multiply(sample_coords[2:], [120,120]).astype(int)), \n",
        "                        (255,0,0), 2)\n",
        "\n",
        "    ax[idx].imshow(sample_image)"
      ],
      "metadata": {
        "id": "sHW_Ze4Mxav9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Build Deep Learning using the Functional API\n",
        "# 8.1 Import Layers and Base Network"
      ],
      "metadata": {
        "id": "p3W5YFWCywxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
        "from tensorflow.keras.applications import VGG16"
      ],
      "metadata": {
        "id": "UApj5d73xfAY"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.2 Download VGG16"
      ],
      "metadata": {
        "id": "RMjGHH9oy3OQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG16(include_top=False)"
      ],
      "metadata": {
        "id": "udI6NAvny0YC"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oZaqBaSy7bg",
        "outputId": "96ac2a22-fef7-479d-ba19-9c0986ed79db"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, None, None, 3)]   0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.3 Build instance of Network"
      ],
      "metadata": {
        "id": "mkPgq95CzArb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(): \n",
        "    input_layer = Input(shape=(120,120,3))\n",
        "    \n",
        "    vgg = VGG16(include_top=False)(input_layer)\n",
        "\n",
        "    # Classification Model  \n",
        "    f1 = GlobalMaxPooling2D()(vgg)\n",
        "    class1 = Dense(2048, activation='relu')(f1)\n",
        "    class2 = Dense(1, activation='sigmoid')(class1)\n",
        "    \n",
        "    # Bounding box model\n",
        "    f2 = GlobalMaxPooling2D()(vgg)\n",
        "    regress1 = Dense(2048, activation='relu')(f2)\n",
        "    regress2 = Dense(4, activation='sigmoid')(regress1)\n",
        "    \n",
        "    facetracker = Model(inputs=input_layer, outputs=[class2, regress2])\n",
        "    return facetracker"
      ],
      "metadata": {
        "id": "7p5uoMzCy9yD"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.as_numpy_iterator().next()[1]"
      ],
      "metadata": {
        "id": "ru_hXWFbzExd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.4 Test out Neural Network"
      ],
      "metadata": {
        "id": "x9Il2T9p4O8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "facetracker = build_model()\n",
        "\n",
        "facetracker.summary()\n"
      ],
      "metadata": {
        "id": "DpUwWkjj3rAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X, y = train.as_numpy_iterator().next()\n",
        "\n",
        "X.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TEuXWa44b4C",
        "outputId": "030e4b33-e258-406b-d07b-017b6412da76"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 120, 120, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classes, coords = facetracker.predict(X)\n",
        "\n",
        "classes, coords"
      ],
      "metadata": {
        "id": "pbftBwIQ4dg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Define Losses and Optimizers\n",
        "# 9.1 Define Optimizer and LR"
      ],
      "metadata": {
        "id": "aYM_Dvjx5Nsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batches_per_epoch = len(train)\n",
        "lr_decay = (1./0.75 -1)/batches_per_epoch\n"
      ],
      "metadata": {
        "id": "6UwscM8t4d5Y"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=lr_decay)"
      ],
      "metadata": {
        "id": "fChQE4825UVj"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.2 Create Localization Loss and Classification Loss"
      ],
      "metadata": {
        "id": "GaRm_yoS5kO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def localization_loss(y_true, yhat):            \n",
        "    delta_coord = tf.reduce_sum(tf.square(y_true[:,:2] - yhat[:,:2]))\n",
        "                  \n",
        "    h_true = y_true[:,3] - y_true[:,1] \n",
        "    w_true = y_true[:,2] - y_true[:,0] \n",
        "\n",
        "    h_pred = yhat[:,3] - yhat[:,1] \n",
        "    w_pred = yhat[:,2] - yhat[:,0] \n",
        "    \n",
        "    delta_size = tf.reduce_sum(tf.square(w_true - w_pred) + tf.square(h_true-h_pred))\n",
        "    \n",
        "    return delta_coord + delta_size"
      ],
      "metadata": {
        "id": "HL0AnLw45Uxn"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classloss = tf.keras.losses.BinaryCrossentropy()\n",
        "regressloss = localization_loss"
      ],
      "metadata": {
        "id": "e5KaeuNP5oDU"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.3 Test out Loss Metrics"
      ],
      "metadata": {
        "id": "beQqvpK55rX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "localization_loss(y[1], coords)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6LlKeu_5pi0",
        "outputId": "5e104a21-5798-493e-e38f-cd7965ba8987"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=5.5520067>"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classloss(y[0], classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVtVT4H06J28",
        "outputId": "3909f618-bf89-420c-c7ba-2ef9e00c4ad2"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.6931021>"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regressloss(y[1], coords)"
      ],
      "metadata": {
        "id": "B96Gy9LH6MUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Train Neural Network\n",
        "# 10.1 Create Custom Model Class"
      ],
      "metadata": {
        "id": "V3HqOhoz6R02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceTracker(Model): \n",
        "    def __init__(self, eyetracker,  **kwargs): \n",
        "        super().__init__(**kwargs)\n",
        "        self.model = eyetracker\n",
        "\n",
        "    def compile(self, opt, classloss, localizationloss, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "        self.closs = classloss\n",
        "        self.lloss = localizationloss\n",
        "        self.opt = opt\n",
        "    \n",
        "    def train_step(self, batch, **kwargs): \n",
        "        \n",
        "        X, y = batch\n",
        "        \n",
        "        with tf.GradientTape() as tape: \n",
        "            classes, coords = self.model(X, training=True)\n",
        "            \n",
        "            batch_classloss = self.closs(y[0], classes)\n",
        "            batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
        "            \n",
        "            total_loss = batch_localizationloss+0.5*batch_classloss\n",
        "            \n",
        "            grad = tape.gradient(total_loss, self.model.trainable_variables)\n",
        "        \n",
        "        opt.apply_gradients(zip(grad, self.model.trainable_variables))\n",
        "        \n",
        "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_localizationloss}\n",
        "    \n",
        "    def test_step(self, batch, **kwargs): \n",
        "        X, y = batch\n",
        "        \n",
        "        classes, coords = self.model(X, training=False)\n",
        "        \n",
        "        batch_classloss = self.closs(y[0], classes)\n",
        "        batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
        "        total_loss = batch_localizationloss+0.5*batch_classloss\n",
        "        \n",
        "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_localizationloss}\n",
        "        \n",
        "    def call(self, X, **kwargs): \n",
        "        return self.model(X, **kwargs)"
      ],
      "metadata": {
        "id": "WxsI-rhr6Mtj"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FaceTracker(facetracker)\n"
      ],
      "metadata": {
        "id": "Xmxg25cC6c-U"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(opt, classloss, regressloss)"
      ],
      "metadata": {
        "id": "ZqYgBMDW6eUM"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.2 Train"
      ],
      "metadata": {
        "id": "tP6aKY_y6h_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logdir='logs'"
      ],
      "metadata": {
        "id": "Jp1XwqZl6fSL"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
      ],
      "metadata": {
        "id": "2BqJE_Kw7RFP"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(train, epochs=10, validation_data=val, callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "id": "i-RkfwQt7StU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.3 Plot Performance"
      ],
      "metadata": {
        "id": "1AwRKgmj7VU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist.history"
      ],
      "metadata": {
        "id": "sznfu0xE7UWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(ncols=3, figsize=(20,5))\n",
        "\n",
        "ax[0].plot(hist.history['total_loss'], color='teal', label='loss')\n",
        "ax[0].plot(hist.history['val_total_loss'], color='orange', label='val loss')\n",
        "ax[0].title.set_text('Loss')\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(hist.history['class_loss'], color='teal', label='class loss')\n",
        "ax[1].plot(hist.history['val_class_loss'], color='orange', label='val class loss')\n",
        "ax[1].title.set_text('Classification Loss')\n",
        "ax[1].legend()\n",
        "\n",
        "ax[2].plot(hist.history['regress_loss'], color='teal', label='regress loss')\n",
        "ax[2].plot(hist.history['val_regress_loss'], color='orange', label='val regress loss')\n",
        "ax[2].title.set_text('Regression Loss')\n",
        "ax[2].legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qo6p2trx7aWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Make Predictions\n",
        "# 11.1 Make Predictions on Test Set"
      ],
      "metadata": {
        "id": "oW_wGATh7egx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = test.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "aUs1s2377cEU"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample = test_data.next()"
      ],
      "metadata": {
        "id": "iaCEWtNO8KIC"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = facetracker.predict(test_sample[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7y4mkqI8KKH",
        "outputId": "5840b5da-d36b-4215-d01f-0f764e21e70e"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
        "for idx in range(4): \n",
        "    sample_image = test_sample[0][idx]\n",
        "    sample_coords = yhat[1][idx]\n",
        "    \n",
        "    if yhat[0][idx] > 0.9:\n",
        "        cv2.rectangle(sample_image, \n",
        "                      tuple(np.multiply(sample_coords[:2], [120,120]).astype(int)),\n",
        "                      tuple(np.multiply(sample_coords[2:], [120,120]).astype(int)), \n",
        "                            (255,0,0), 2)\n",
        "    \n",
        "    ax[idx].imshow(sample_image)"
      ],
      "metadata": {
        "id": "8MLQLhgw8KL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11.2 Save the Model"
      ],
      "metadata": {
        "id": "JkQrjmQS8aX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "facetracker.save('facetracker.h5')\n",
        "facetracker = load_model('facetracker.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rrZh0o38KSE",
        "outputId": "09de4e28-0e49-426f-8fbc-39f447773bb7"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11.3 Real Time Detection"
      ],
      "metadata": {
        "id": "jHTd7iwF98of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(1)\n",
        "while cap.isOpened():\n",
        "    _ , frame = cap.read()\n",
        "    frame = frame[50:500, 50:500,:]\n",
        "    \n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    resized = tf.image.resize(rgb, (120,120))\n",
        "    \n",
        "    yhat = facetracker.predict(np.expand_dims(resized/255,0))\n",
        "    sample_coords = yhat[1][0]\n",
        "    \n",
        "    if yhat[0] > 0.5: \n",
        "        # Controls the main rectangle\n",
        "        cv2.rectangle(frame, \n",
        "                      tuple(np.multiply(sample_coords[:2], [450,450]).astype(int)),\n",
        "                      tuple(np.multiply(sample_coords[2:], [450,450]).astype(int)), \n",
        "                            (255,0,0), 2)\n",
        "        # Controls the label rectangle\n",
        "        cv2.rectangle(frame, \n",
        "                      tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int), \n",
        "                                    [0,-30])),\n",
        "                      tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
        "                                    [80,0])), \n",
        "                            (255,0,0), -1)\n",
        "        \n",
        "        # Controls the text rendered\n",
        "        cv2.putText(frame, 'face', tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
        "                                               [0,-5])),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
        "    \n",
        "    cv2.imshow('EyeTrack', frame)\n",
        "    \n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "hFmkxNkxEzPi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}